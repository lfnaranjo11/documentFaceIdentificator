<!DOCTYPE html>
<html>
  <head>
    <script src="./public/js/face-api.js"></script>

    <meta content="text/html;charset=utf-8" http-equiv="Content-Type" />
    <meta content="utf-8" http-equiv="encoding" />
    <link rel="shortcut icon" href="#" />
  </head>
  <body>
    <canvas id="id_you_like"></canvas>
    <video
      autoplay="true"
      id="videoElement"
      width="100%"
      height="100%"
      muted
    ></video>
  </body>
  <style>
    canvas {
      position: absolute;
      z-index: 10;
      top: 0;
      left: 0;
      background-color: rgba(255, 0, 0, 0.2);
    }
  </style>
  <script>
    const canvas = document.querySelector('#id_you_like');
    var refreshSquare;
    canvas.setAttribute('width', window.innerWidth);
    canvas.setAttribute('height', window.innerHeight);
    var video = document.querySelector('#videoElement');
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('./public/models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('./public/models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('./public/models'),
    ])
      .then(startVideo)
      .catch((e) => {
        console.log(e);
      });

    video.setAttribute('width', window.innerWidth);
    video.setAttribute('height', window.innerHeight);
    var ctx = canvas.getContext('2d');
    var video = document.querySelector('#videoElement');

    function startVideo() {
      if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices
          .getUserMedia({ video: { facingMode: 'environment' } })
          .then(function (stream) {
            video.srcObject = stream;
          })
          .catch(function (err0r) {
            console.log('Something went wrong!');
          });
      }
    }
    video.addEventListener('play', () => {
      var targetStillnes = 5;
      var stillenes = 0;
      var posicionX = 0;
      var posicionY = 0;
      const displaySize = { width: video.width, height: video.height };
      refreshSquare = setInterval(async () => {
        console.log('sigue');
        const detections = await faceapi.detectSingleFace(
          video,
          new faceapi.TinyFaceDetectorOptions()
        );

        if (detections) {
          const detectionsForSize = faceapi.resizeResults(detections, {
            width: video.width,
            height: video.height,
          });
          canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);

          if (
            isStill(
              posicionX,
              posicionY,
              detections._box._x,
              detections._box._y
            )
          ) {
            stillenes += 1;
          } else {
            stillenes = 0;
          }
          if (stillenes == targetStillnes) {
            console.log('taking sc');
            doScreenshot();
          }
          faceapi.draw.drawDetections(canvas, detectionsForSize);
          posicionX = detections._box._x;
          posicionY = detections._box._y;
        }
      }, 700);
    });

    const isStill = (oldX, oldY, x, y) => {
      if (Math.sqrt(Math.pow(oldX - x, 2) + Math.pow(oldY - y, 2)) < 10) {
        return true;
      }
      return false;
    };
    const doScreenshot = () => {
      clearInterval(refreshSquare);
      video.pause();
      // canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
    };
  </script>
</html>
